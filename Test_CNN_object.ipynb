{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=\"data/\"\n",
    "data=pd.read_csv(path+\"input_train.csv\", index_col=\"ID\")\n",
    "X_ACC=data.filter(regex= \"ACC*\")\n",
    "X_EEG=data.filter(regex= \"EEG*\")\n",
    "labels=pd.read_csv(path+\"challenge_output_data_training_file_sleep_stages_classification.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test=pd.read_csv(path+\"input_test.csv\", index_col=\"ID\")\n",
    "X_ACC_TEST=data_test.filter(regex= \"ACC*\")\n",
    "X_EEG_TEST=data_test.filter(regex= \"EEG*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def train_val_test_split(X):    \n",
    "    X_train, X_test = train_test_split(X, test_size=0.10, random_state=42)\n",
    "    X_train, X_val = train_test_split(X_train, test_size=0.10, random_state=42)\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ACC_train, X_ACC_val, X_ACC_test=train_val_test_split(X_ACC)\n",
    "X_EEG_train, X_EEG_val, X_EEG_test=train_val_test_split(X_EEG)\n",
    "y_train, y_val, y_test=train_val_test_split(labels[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ACC_TEST.shape, X_ACC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30458, 450)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ACC_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_ACC_train = StandardScaler().fit(X_ACC_train)\n",
    "scaler_EEG_train= StandardScaler().fit(X_EEG_train)\n",
    "scaler_ACC_predict = StandardScaler().fit(X_ACC)\n",
    "scaler_EEG_predict= StandardScaler().fit(X_EEG)\n",
    "\n",
    "X_ACC_train=scaler_ACC_train.transform(X_ACC_train)\n",
    "X_ACC_val=scaler_ACC_train.transform(X_ACC_val)\n",
    "X_ACC_test=scaler_ACC_train.transform(X_ACC_test)\n",
    "\n",
    "X_EEG_train=scaler_EEG_train.transform(X_EEG_train)\n",
    "X_EEG_val=scaler_EEG_train.transform(X_EEG_val)\n",
    "X_EEG_test=scaler_EEG_train.transform(X_EEG_test)\n",
    "\n",
    "X_ACC=scaler_ACC_predict.transform(X_ACC)\n",
    "X_EEG=scaler_EEG_predict.transform(X_EEG)\n",
    "\n",
    "X_ACC_TEST=scaler_ACC_predict.transform(X_ACC_TEST)\n",
    "X_EEG_TEST=scaler_EEG_predict.transform(X_EEG_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape(X, n_channels):\n",
    "    return X.reshape(X.shape[0],n_channels,X.shape[1]/n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_EEG_train=reshape(X_EEG_train,1)\n",
    "X_EEG_val=reshape(X_EEG_val,1)\n",
    "X_EEG_test=reshape(X_EEG_test,1)\n",
    "X_EEG=reshape(X_EEG,1)\n",
    "X_EEG_TEST=reshape(X_EEG_TEST,1)\n",
    "\n",
    "X_ACC_train=reshape(X_ACC_train,3)\n",
    "X_ACC_val=reshape(X_ACC_val,3)\n",
    "X_ACC_test=reshape(X_ACC_test,3)\n",
    "X_ACC=reshape(X_ACC,3)\n",
    "X_ACC_TEST=reshape(X_ACC_TEST,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input_var_EEG = T.tensor3('inputs')\n",
    "input_var_ACC = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "# Create neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.base import BaseEstimator\n",
    "def iterate_minibatches(input_1, input_2, targets, batchsize, shuffle=False):\n",
    "    assert len(input_1) == len(targets)\n",
    "    assert len(input_2) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(input_1))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(input_1) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield input_1[excerpt], input_2[excerpt], targets[excerpt]\n",
    "\n",
    "\"\"\"Default variables\"\"\"\n",
    "num_epochs = 1\n",
    "EEG_shape_1=X_EEG_train.shape[1]\n",
    "EEG_shape_2=X_EEG_train.shape[2]\n",
    "ACC_shape_1=X_ACC_train.shape[1]\n",
    "ACC_shape_2=X_ACC_train.shape[2]\n",
    "n_filters_EEG_1=32\n",
    "#n_filters_EEG_2=\n",
    "n_filters_ACC_1=16\n",
    "#n_filters_ACC_2=\n",
    "filter_size_EEG_1=100\n",
    "#filter_size_EEG_2=\n",
    "filter_size_ACC_1=8\n",
    "#filter_size_ACC_2=\n",
    "pool_size_EEG=25\n",
    "pool_size_ACC=2\n",
    "drop_out=0.7\n",
    "init_learning_rate=0.01\n",
    "num_units_EEG=1000\n",
    "num_units_ACC=100\n",
    "num_units_pool=1000\n",
    "num_classes=5\n",
    "\n",
    "class CNN(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_var_EEG, \n",
    "        input_var_ACC, \n",
    "        target_var,\n",
    "        num_epochs\n",
    "    ):\n",
    "        #setting variables\n",
    "        self.input_var_EEG=input_var_EEG\n",
    "        self.input_var_ACC=input_var_ACC\n",
    "        self.target_var=target_var    \n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        #The network\n",
    "        #Two initialisation layers\n",
    "        #One for EEG\n",
    "        self.l_in1 = lasagne.layers.InputLayer(\n",
    "            shape=(None,EEG_shape_1, EEG_shape_2),\n",
    "            input_var=self.input_var_EEG\n",
    "        )\n",
    "        #One for ACC\n",
    "        self.l_in2 = lasagne.layers.InputLayer(\n",
    "            shape=(None,ACC_shape_1, ACC_shape_2),\n",
    "            input_var=self.input_var_ACC\n",
    "        )\n",
    "        #Two convolutional layers to treat each signal separatedly\n",
    "        self.l_conv1_1 = lasagne.layers.Conv1DLayer(\n",
    "            self.l_in1, \n",
    "            num_filters=n_filters_EEG_1, \n",
    "            filter_size=filter_size_EEG_1,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotNormal()\n",
    "        )\n",
    "        self.l_conv2_1 = lasagne.layers.Conv1DLayer(\n",
    "            self.l_in2, \n",
    "            num_filters=n_filters_ACC_1, \n",
    "            filter_size=filter_size_ACC_1,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotNormal()\n",
    "        )\n",
    "        #And again another 2 layers\n",
    "        \"\"\"l_conv1_2 = lasagne.layers.Conv1DLayer(\n",
    "            l_conv1_1, num_filters=16, filter_size=50,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "        l_conv2_2 = lasagne.layers.Conv1DLayer(\n",
    "            l_conv2_1, num_filters=16, filter_size=5,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "        \"\"\"\n",
    "        #And two pooling layers\n",
    "        \"\"\"l_pool1 = lasagne.layers.MaxPool1DLayer(l_conv1_2, pool_size=25)\n",
    "        l_pool2 = lasagne.layers.MaxPool1DLayer(l_conv2_2, pool_size=2)\n",
    "        \"\"\"\n",
    "        self.l_pool1 = lasagne.layers.MaxPool1DLayer(\n",
    "            self.l_conv1_1, \n",
    "            pool_size=pool_size_EEG\n",
    "        )\n",
    "        self.l_pool2 = lasagne.layers.MaxPool1DLayer(\n",
    "            self.l_conv2_1, \n",
    "            pool_size=pool_size_ACC\n",
    "        )    \n",
    "        #Two dense layers for each signal\n",
    "        self.l_dense_1_1 = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(\n",
    "                self.l_pool1, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_EEG,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        self.l_dense_2_1 = lasagne.layers.DenseLayer(\n",
    "                lasagne.layers.dropout(\n",
    "                self.l_pool2, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_ACC,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        #use neurons from both signals to predict\n",
    "        #concatenate neurons\n",
    "        self.l_concat = lasagne.layers.ConcatLayer(\n",
    "            [\n",
    "                self.l_dense_1_1, \n",
    "                self.l_dense_2_1\n",
    "            ], \n",
    "            axis=1\n",
    "        )\n",
    "        #dense layer with all neurons\n",
    "        self.l_dense_2 = lasagne.layers.DenseLayer(\n",
    "                lasagne.layers.dropout(\n",
    "                self.l_concat, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_pool,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        #Output layer\n",
    "        self.l_output = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(\n",
    "                self.l_dense_2, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_classes,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax\n",
    "        )\n",
    "        self.prediction = lasagne.layers.get_output(self.l_output)\n",
    "        self.loss = lasagne.objectives.multiclass_hinge_loss(self.prediction, target_var)\n",
    "        self.loss = self.loss.mean()\n",
    "        self.params = lasagne.layers.get_all_params(self.l_output, trainable=True)\n",
    "        self.updates = lasagne.updates.adadelta(\n",
    "            self.loss, \n",
    "            self.params, \n",
    "            learning_rate=init_learning_rate\n",
    "        )\n",
    "        self.test_prediction = lasagne.layers.get_output(self.l_output, deterministic=True)\n",
    "        self.test_loss = lasagne.objectives.multiclass_hinge_loss(self.test_prediction,\n",
    "                                                                target_var)\n",
    "        self.test_loss = self.test_loss.mean()\n",
    "        self.test_acc = T.mean(T.eq(T.argmax(self.test_prediction, axis=1), self.target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "        self.train_fn =theano.function(\n",
    "            [self.input_var_EEG, self.input_var_ACC, self.target_var], \n",
    "            self.loss, \n",
    "            updates=self.updates\n",
    "        )\n",
    "        self.val_fn = theano.function(\n",
    "            [self.input_var_EEG, \n",
    "             self.input_var_ACC,\n",
    "             self.target_var\n",
    "            ], \n",
    "            [self.test_loss, self.test_acc])\n",
    "    def fit(self,X_EEG_train,X_ACC_train,X_EEG_val,X_ACC_val,y_train,y_val):\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # In each epoch, we do a full pass over the training data:\n",
    "            train_err = 0\n",
    "            train_batches = 0\n",
    "            start_time = time.time()\n",
    "            for batch in iterate_minibatches(X_EEG_train, X_ACC_train, y_train, 64, shuffle=True):\n",
    "                input_1, input_2, targets = batch\n",
    "                targets = targets.astype(np.int32)\n",
    "                train_err += self.train_fn(input_1, input_2, targets)\n",
    "                train_batches += 1\n",
    "                if train_batches % 100 == 0:\n",
    "                    print \"epoch {}, train batches{}\".format(epoch,train_batches) \n",
    "\n",
    "            # And a full pass over the validation data:\n",
    "            val_err = 0\n",
    "            val_acc = 0\n",
    "            val_batches = 0\n",
    "            for batch in iterate_minibatches(X_EEG_val, X_ACC_val, y_val, 128, shuffle=False):\n",
    "                input_1, input_2, targets = batch\n",
    "                targets = targets.astype(np.int32)\n",
    "                err, acc = self.val_fn(input_1, input_2, targets)\n",
    "                val_err += err\n",
    "                val_acc += acc\n",
    "                val_batches += 1\n",
    "\n",
    "            # Then we print the results for this epoch:\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "            print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "            print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "            print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "                val_acc / val_batches * 100))\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self,X_EEG_test, X_ACC_test):\n",
    "        net_output=lasagne.layers.get_output(self.l_output, deterministic=True)\n",
    "        prediction_fn = theano.function([input_var_EEG, input_var_ACC], [net_output])\n",
    "        prediction =  prediction_fn(X_EEG_test, X_ACC_test)\n",
    "        return prediction[0]\n",
    "\n",
    "    def predict(self,X_EEG_test, X_ACC_test):\n",
    "         return np.argmax(self.predict_proba(X_EEG_test, X_ACC_test), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn=CNN(input_var_EEG, \n",
    "        input_var_ACC, \n",
    "        target_var,\n",
    "        num_epochs\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train batches100\n",
      "epoch 0, train batches200\n",
      "epoch 0, train batches300\n",
      "Epoch 1 of 1 took 261.688s\n",
      "  training loss:\t\t1.064237\n",
      "  validation loss:\t\t1.007201\n",
      "  validation accuracy:\t\t49.67 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(input_var_ACC=inputs, input_var_EEG=inputs, num_epochs=1,\n",
       "  target_var=targets)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_EEG_train, X_ACC_train, X_EEG_val, X_ACC_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14021251,  0.11619791,  0.35786882,  0.2419734 ,  0.14374737],\n",
       "       [ 0.11177684,  0.10079557,  0.48230405,  0.16996395,  0.1351596 ],\n",
       "       [ 0.121304  ,  0.11671714,  0.39195205,  0.23015233,  0.13987448],\n",
       "       ..., \n",
       "       [ 0.0364896 ,  0.03863931,  0.53840717,  0.34013839,  0.04632554],\n",
       "       [ 0.09384441,  0.09309949,  0.47041411,  0.22740766,  0.11523433],\n",
       "       [ 0.002091  ,  0.00123766,  0.40399347,  0.59097655,  0.00170132]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict_proba(X_EEG_test, X_ACC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict(X_EEG_test, X_ACC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
