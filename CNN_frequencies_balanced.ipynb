{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from sys import platform as _platform\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "#if _platform =='linux2':\n",
    "#    path = '../data/data_sleep/' \n",
    "#else:\n",
    "#    #mets ton path ici et Ã§a devrait marcher :)\n",
    "#    path = \"\"\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#frequencies=pd.read_csv(path+\"data_frequences.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "frequencies=pd.read_csv(path+\"fft_eeg.csv\")\n",
    "frequencies_acc =pd.read_csv(path+\"fft_acc.csv\", index_col=\"ID\")\n",
    "\n",
    "stats=pd.read_csv(path+\"data_stat_feats.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "labels=pd.read_csv(path+\"challenge_output_data_training_file_sleep_stages_classification.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_freq_names(low, high, X_columns, prefix = ''):\n",
    "    return [name for name in X_columns \n",
    "            if len(name.split('q'))==2 \n",
    "            and name.split('freq')[0] == prefix\n",
    "            and low<=float(name.split('freq')[1]) \n",
    "            and high>= float(name.split('freq')[1])]\n",
    "def group_frequencies(name, low, high, frequencies, prefix = ''):\n",
    "    frequencies[name]=(1./(high-low) * (frequencies[select_freq_names(low,high,frequencies.columns,prefix)])).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_feat = [\"delta\", 'theta', 'alpha1','alpha2', 'beta']\n",
    "#frequencies[\"delta\"]=frequencies[select_freq_names(0,3,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"delta\"]=frequencies[select_freq_names(0,3.99,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"theta\"]=frequencies[select_freq_names(4,7.5,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"alpha\"]=frequencies[select_freq_names(7.5,13.99,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"beta\"]=frequencies[select_freq_names(14,50,frequencies.columns)].sum(axis=1)\n",
    "\n",
    "def make_new_feats(frequencies):\n",
    "    group_frequencies(\"delta\", 0.8, 3.99, frequencies)\n",
    "    group_frequencies(\"theta\", 4, 7.499, frequencies)\n",
    "    group_frequencies(\"alpha1\", 7.5, 9.5, frequencies)\n",
    "    group_frequencies(\"alpha2\", 9.5, 13.99, frequencies)\n",
    "    group_frequencies(\"beta\", 14, 50, frequencies)\n",
    "#make_new_feats(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def train_val_test_split(X):    \n",
    "    X_train, X_test = train_test_split(X, test_size=0.10, random_state=42)\n",
    "    X_train, X_val = train_test_split(X_train, test_size=0.10, random_state=42)\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ACC_train, X_ACC_val, X_ACC_test=train_val_test_split(frequencies_acc)\n",
    "X_EEG_train, X_EEG_val, X_EEG_test=train_val_test_split(frequencies)\n",
    "X_other_train, X_other_val, X_other_test=train_val_test_split(stats.drop([\"skew_ACC_X\",\"skew_ACC_Y\", \"skew_ACC_Z\"], axis=1))\n",
    "y_train, y_val, y_test=train_val_test_split(labels[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_ACC=scaler_ACC_predict.transform(X_ACC)\\nX_EEG=scaler_EEG_predict.transform(X_EEG)\\n\\nX_ACC_TEST=scaler_ACC_predict.transform(X_ACC_TEST)\\nX_EEG_TEST=scaler_EEG_predict.transform(X_EEG_TEST)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler_ACC_train = StandardScaler().fit(X_ACC_train)\n",
    "scaler_EEG_train= StandardScaler().fit(X_EEG_train)\n",
    "scaler_other_train=StandardScaler().fit(X_other_train)\n",
    "\"\"\"\n",
    "scaler_ACC_predict = StandardScaler().fit(X_ACC)\n",
    "scaler_EEG_predict= StandardScaler().fit(X_EEG)\n",
    "\"\"\"\n",
    "\n",
    "X_ACC_train=scaler_ACC_train.transform(X_ACC_train)\n",
    "X_ACC_val=scaler_ACC_train.transform(X_ACC_val)\n",
    "X_ACC_test=scaler_ACC_train.transform(X_ACC_test)\n",
    "\n",
    "X_EEG_train=scaler_EEG_train.transform(X_EEG_train)\n",
    "X_EEG_val=scaler_EEG_train.transform(X_EEG_val)\n",
    "X_EEG_test=scaler_EEG_train.transform(X_EEG_test)\n",
    "\n",
    "X_other_train=scaler_other_train.transform(X_other_train)\n",
    "X_other_val=scaler_other_train.transform(X_other_val)\n",
    "X_other_test=scaler_other_train.transform(X_other_test)\n",
    "\n",
    "\"\"\"\n",
    "X_ACC=scaler_ACC_predict.transform(X_ACC)\n",
    "X_EEG=scaler_EEG_predict.transform(X_EEG)\n",
    "\n",
    "X_ACC_TEST=scaler_ACC_predict.transform(X_ACC_TEST)\n",
    "X_EEG_TEST=scaler_EEG_predict.transform(X_EEG_TEST)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_num=pd.DataFrame([range(len(y_train)), list(y_train)], index=[\"ID\",\"y\"]).T.groupby(\"y\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extra_sample(label, X_EEG_train, X_ACC_train, X_other_train):\n",
    "    random_indices=np.random.randint(0,labels_num.loc[label], labels_num.max()-labels_num.loc[label])\n",
    "    EEG=X_EEG_train[random_indices]\n",
    "    ACC=X_ACC_train[random_indices]\n",
    "    other=X_other_train[random_indices]\n",
    "    return EEG, ACC, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/pandas/core/indexing.py:1198: FutureWarning: scalar indexers for index type Float64Index should be integers and not floating point\n",
      "  return self._getitem_axis(key, axis=0)\n"
     ]
    }
   ],
   "source": [
    "X_EEG_train_l=(X_EEG_train,)\n",
    "X_ACC_train_l=(X_ACC_train,)\n",
    "X_other_train_l=(X_other_train,)\n",
    "for label in labels[\"TARGET\"].unique():\n",
    "    if (labels_num.iloc[label].values < labels_num.max())[0]:\n",
    "        sample=extra_sample(label, X_EEG_train, X_ACC_train, X_other_train)\n",
    "        X_EEG_train_l=X_EEG_train_l + (sample[0],)\n",
    "        X_ACC_train_l=X_ACC_train_l + (sample[1],)\n",
    "        X_other_train_l=X_other_train_l + (sample[2],)\n",
    "X_EEG_trs=np.concatenate(X_EEG_train_l, axis=0)\n",
    "X_ACC_trs=np.concatenate(X_ACC_train_l, axis=0)\n",
    "X_other_trs=np.concatenate(X_other_train_l, axis=0)\n",
    "y_trs=np.concatenate(\n",
    "    (y_train,) + tuple(\n",
    "        [np.array([label]*(labels_num.max()-labels_num.loc[label])[0]) for label in labels[\"TARGET\"].unique()]\n",
    "                      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regroup_acc_freq (frequencies_acc):\n",
    "    for prefix in ['ACC_X.','ACC_Y.','ACC_Z.']:\n",
    "        group_frequencies(prefix+\"smaller_one\",0.01,1, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"one_to_two\",1.01,2, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"two_to_three\",2.01,3, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"three_to_four\",3.01,4, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"more_four\",4,10, frequencies_acc,prefix)\n",
    "#regroup_acc_freq (frequencies_acc)\n",
    "\n",
    "#prefixes = ['ACC_X.','ACC_Y.','ACC_Z.']\n",
    "#frequencies_acc = frequencies_acc[[prefix+ x for x in[\"smaller_one\",\"one_to_two\",\"two_to_three\",'more_four']for prefix in prefixes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reshape(X, n_channels):\n",
    "    return X.reshape(X.shape[0],n_channels,X.shape[1]/n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ACC_trs=reshape(X_ACC_trs,3)\n",
    "X_ACC_val=reshape(X_ACC_val,3)\n",
    "X_ACC_test=reshape(X_ACC_test,3)\n",
    "\n",
    "X_EEG_trs=reshape(X_EEG_trs,1)\n",
    "X_EEG_val=reshape(X_EEG_val,1)\n",
    "X_EEG_test=reshape(X_EEG_test,1)\n",
    "\n",
    "X_other_trs=reshape(X_other_trs,1)\n",
    "X_other_val=reshape(X_other_val,1)\n",
    "X_other_test=reshape(X_other_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input_var_EEG = T.tensor3('inputs')\n",
    "input_var_ACC = T.tensor3('inputs')\n",
    "input_var_other = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "# Create neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.base import BaseEstimator\n",
    "def iterate_minibatches(\n",
    "    input_1, \n",
    "    input_2, \n",
    "    input_3,\n",
    "    targets, \n",
    "    batchsize, \n",
    "    shuffle=False\n",
    "):\n",
    "    assert len(input_1) == len(targets)\n",
    "    assert len(input_2) == len(targets)\n",
    "    assert len(input_3) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(input_1))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(input_1) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield input_1[excerpt], input_2[excerpt], input_3[excerpt], targets[excerpt]\n",
    "\n",
    "\"\"\"Default variables\"\"\"\n",
    "num_epochs = 20\n",
    "EEG_shape_1=X_EEG_trs.shape[1]\n",
    "EEG_shape_2=X_EEG_trs.shape[2]\n",
    "ACC_shape_1=X_ACC_trs.shape[1]\n",
    "ACC_shape_2=X_ACC_trs.shape[2]\n",
    "other_shape_1=X_other_trs.shape[1]\n",
    "other_shape_2=X_other_trs.shape[2]\n",
    "n_filters_EEG_1=32\n",
    "n_filters_EEG_2=32\n",
    "n_filters_ACC_1=16\n",
    "n_filters_ACC_2=16\n",
    "filter_size_EEG_1=32\n",
    "filter_size_EEG_2=8\n",
    "filter_size_ACC_1=8\n",
    "filter_size_ACC_2=4\n",
    "pool_size_EEG_1=16\n",
    "pool_size_EEG_2=4\n",
    "pool_size_ACC_1=16\n",
    "pool_size_ACC_2=4\n",
    "drop_out=0.5\n",
    "init_learning_rate=0.01\n",
    "num_units_EEG=1000\n",
    "num_units_ACC=100\n",
    "num_units_concat=2000\n",
    "num_units_other=1000\n",
    "num_classes=5\n",
    "\n",
    "class CNN(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_var_EEG, \n",
    "        input_var_ACC,\n",
    "        input_var_other,\n",
    "        target_var,\n",
    "        num_epochs\n",
    "    ):\n",
    "        #setting variables\n",
    "        self.input_var_EEG=input_var_EEG\n",
    "        self.input_var_ACC=input_var_ACC\n",
    "        self.input_var_other=input_var_other\n",
    "        self.target_var=target_var    \n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        #The network\n",
    "        #Three initialisation layers\n",
    "        #One for EEG\n",
    "        self.l_in1 = lasagne.layers.InputLayer(\n",
    "            shape=(None,EEG_shape_1, EEG_shape_2),\n",
    "            input_var=self.input_var_EEG\n",
    "        )\n",
    "        #One for ACC\n",
    "        self.l_in2 = lasagne.layers.InputLayer(\n",
    "            shape=(None,ACC_shape_1, ACC_shape_2),\n",
    "            input_var=self.input_var_ACC\n",
    "        )\n",
    "        self.l_in3=lasagne.layers.InputLayer(\n",
    "            shape=(None,other_shape_1, other_shape_2),\n",
    "            input_var=self.input_var_other\n",
    "        )\n",
    "        #Two convolutional layers to treat each signal separatedly\n",
    "        self.l_conv1_1 = lasagne.layers.Conv1DLayer(\n",
    "            self.l_in1, \n",
    "            num_filters=n_filters_EEG_1, \n",
    "            filter_size=filter_size_EEG_1,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotNormal()\n",
    "        )\n",
    "        self.l_conv2_1 = lasagne.layers.Conv1DLayer(\n",
    "            self.l_in2, \n",
    "            num_filters=n_filters_ACC_1, \n",
    "            filter_size=filter_size_ACC_1,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotNormal()\n",
    "        )\n",
    "        #And two pooling layers\n",
    "\n",
    "        self.l_pool_1_1 = lasagne.layers.MaxPool1DLayer(\n",
    "            self.l_conv1_1, \n",
    "            pool_size=pool_size_EEG_1\n",
    "        )\n",
    "        self.l_pool_2_1 = lasagne.layers.MaxPool1DLayer(\n",
    "            self.l_conv2_1, \n",
    "            pool_size=pool_size_ACC_1\n",
    "        )\n",
    "        #And again another 2 layers\n",
    "        self.l_conv1_2 = lasagne.layers.Conv1DLayer(\n",
    "            self.l_pool_1_1, \n",
    "            num_filters=n_filters_EEG_2, \n",
    "            filter_size=filter_size_EEG_2,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform()\n",
    "        )\n",
    "        self.l_conv2_2 = lasagne.layers.Conv1DLayer(\n",
    "            self.l_conv2_1, num_filters=16, filter_size=5,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "        #pool\n",
    "        self.l_pool_1_2 = lasagne.layers.MaxPool1DLayer(\n",
    "            self.l_conv1_2, \n",
    "            pool_size=pool_size_EEG_2\n",
    "        )\n",
    "        self.l_pool_2_2 = lasagne.layers.MaxPool1DLayer(\n",
    "            self.l_conv2_2, \n",
    "            pool_size=pool_size_ACC_2\n",
    "        )\n",
    "        #Dense layer for \"others\" :\n",
    "        self.l_dense_other = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(\n",
    "                self.l_in3, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_other,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        #Two dense layers for each signal\n",
    "        self.l_dense_1_1 = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(\n",
    "                self.l_pool_1_2, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_EEG,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        self.l_dense_2_1 = lasagne.layers.DenseLayer(\n",
    "                lasagne.layers.dropout(\n",
    "                self.l_pool_2_2, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_ACC,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        #use neurons from both signals to predict\n",
    "        #concatenate neurons\n",
    "        self.l_concat = lasagne.layers.ConcatLayer(\n",
    "            [\n",
    "                #self.l_pool_1_2, \n",
    "                #self.l_pool_2_2,\n",
    "                self.l_dense_1_1,\n",
    "                self.l_dense_2_1,\n",
    "                self.l_dense_other\n",
    "            ], \n",
    "            axis=1\n",
    "        )\n",
    "        #dense layer with all neurons\n",
    "        self.l_dense_2 = lasagne.layers.DenseLayer(\n",
    "                lasagne.layers.dropout(\n",
    "                self.l_concat, \n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_units_concat,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify\n",
    "        )\n",
    "        #Output layer\n",
    "        self.l_output = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(\n",
    "                self.l_dense_2, \n",
    "                #self.l_pool_1_2,\n",
    "                p=drop_out\n",
    "            ),\n",
    "            num_units=num_classes,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax\n",
    "        )\n",
    "        self.prediction = lasagne.layers.get_output(self.l_output)\n",
    "        self.loss = lasagne.objectives.multiclass_hinge_loss(self.prediction, target_var)\n",
    "        self.loss = self.loss.mean()\n",
    "        self.params = lasagne.layers.get_all_params(self.l_output, trainable=True)\n",
    "        self.updates = lasagne.updates.adadelta(\n",
    "            self.loss, \n",
    "            self.params, \n",
    "            learning_rate=init_learning_rate\n",
    "        )\n",
    "        self.test_prediction = lasagne.layers.get_output(self.l_output, deterministic=True)\n",
    "        self.test_loss = lasagne.objectives.multiclass_hinge_loss(self.test_prediction,\n",
    "                                                                target_var)\n",
    "        self.test_loss = self.test_loss.mean()\n",
    "        self.test_acc = T.mean(T.eq(T.argmax(self.test_prediction, axis=1), self.target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "        self.train_fn =theano.function(\n",
    "            [\n",
    "                self.input_var_EEG, \n",
    "                self.input_var_ACC,\n",
    "                self.input_var_other,\n",
    "                self.target_var\n",
    "            ], \n",
    "            self.loss, \n",
    "            updates=self.updates\n",
    "        )\n",
    "        self.val_fn = theano.function(\n",
    "            [\n",
    "                self.input_var_EEG, \n",
    "                self.input_var_ACC,\n",
    "                self.input_var_other,\n",
    "                self.target_var\n",
    "            ], \n",
    "            [self.test_loss, self.test_acc])\n",
    "    def fit(\n",
    "        self,X_EEG_train,\n",
    "        X_ACC_train,\n",
    "        X_other_train,\n",
    "        X_EEG_val,\n",
    "        X_ACC_val,\n",
    "        X_other_val,\n",
    "        y_train,\n",
    "        y_val\n",
    "    ):\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # In each epoch, we do a full pass over the training data:\n",
    "            train_err = 0\n",
    "            train_batches = 0\n",
    "            start_time = time.time()\n",
    "            for batch in iterate_minibatches(\n",
    "                X_EEG_train, \n",
    "                X_ACC_train, \n",
    "                X_other_train,\n",
    "                y_train, \n",
    "                64, \n",
    "                shuffle=True\n",
    "            ):\n",
    "                input_1, input_2, input_3, targets = batch\n",
    "                #inputs, targets = batch\n",
    "                targets = targets.astype(np.int32)\n",
    "                train_err += self.train_fn(input_1, input_2, input_3, targets)\n",
    "                #train_err += self.train_fn(inputs, targets)\n",
    "                train_batches += 1\n",
    "                if train_batches % 100 == 0:\n",
    "                    print \"epoch {}, train batches{}\".format(epoch,train_batches) \n",
    "\n",
    "            # And a full pass over the validation data:\n",
    "            val_err = 0\n",
    "            val_acc = 0\n",
    "            val_batches = 0\n",
    "            for batch in iterate_minibatches(\n",
    "                X_EEG_val, \n",
    "                X_ACC_val, \n",
    "                X_other_val,\n",
    "                y_val, \n",
    "                128, \n",
    "                shuffle=False\n",
    "            ):\n",
    "                input_1, input_2, input_3, targets = batch\n",
    "                #inputs, targets = batch\n",
    "                targets = targets.astype(np.int32)\n",
    "                err, acc = self.val_fn(input_1, input_2, input_3, targets)\n",
    "                #err, acc = self.val_fn(inputs, targets)\n",
    "                val_err += err\n",
    "                val_acc += acc\n",
    "                val_batches += 1\n",
    "\n",
    "            # Then we print the results for this epoch:\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "            print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "            print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "            print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "                val_acc / val_batches * 100))\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(\n",
    "        self,\n",
    "        X_EEG_test, \n",
    "        X_ACC_test,\n",
    "        X_other_test\n",
    "    ):\n",
    "        net_output=lasagne.layers.get_output(self.l_output, deterministic=True)\n",
    "        prediction_fn = theano.function(\n",
    "            [\n",
    "                input_var_EEG, \n",
    "                input_var_ACC,\n",
    "                input_var_other\n",
    "            ], \n",
    "            [net_output]\n",
    "        )\n",
    "        prediction =  prediction_fn(\n",
    "            X_EEG_test, \n",
    "            X_ACC_test,\n",
    "            X_other_test\n",
    "        )\n",
    "        return prediction[0]\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        X_EEG_test, \n",
    "        X_ACC_test,\n",
    "        X_other_test\n",
    "    ):\n",
    "         return np.argmax(self.predict_proba(\n",
    "                    X_EEG_test, \n",
    "                    X_ACC_test,\n",
    "                    X_other_test\n",
    "                ), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn=CNN(input_var_EEG,\n",
    "        input_var_ACC,\n",
    "        input_var_other,\n",
    "        target_var,\n",
    "        num_epochs\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train batches100\n",
      "epoch 0, train batches200\n",
      "epoch 0, train batches300\n",
      "epoch 0, train batches400\n",
      "epoch 0, train batches500\n",
      "epoch 0, train batches600\n",
      "epoch 0, train batches700\n",
      "epoch 0, train batches800\n",
      "epoch 0, train batches900\n",
      "Epoch 1 of 20 took 485.890s\n",
      "  training loss:\t\t1.070876\n",
      "  validation loss:\t\t0.997366\n",
      "  validation accuracy:\t\t51.56 %\n",
      "epoch 1, train batches100\n",
      "epoch 1, train batches200\n",
      "epoch 1, train batches300\n",
      "epoch 1, train batches400\n",
      "epoch 1, train batches500\n",
      "epoch 1, train batches600\n",
      "epoch 1, train batches700\n",
      "epoch 1, train batches800\n",
      "epoch 1, train batches900\n",
      "Epoch 2 of 20 took 441.318s"
     ]
    }
   ],
   "source": [
    "cnn.fit(\n",
    "    X_EEG_trs,\n",
    "    X_ACC_trs,\n",
    "    X_other_trs,\n",
    "    X_EEG_val,\n",
    "    X_ACC_val,\n",
    "    X_other_val,\n",
    "    y_trs,\n",
    "    y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas=cnn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=cnn.predict(X_EEG_test, X_ACC_test, X_other_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2.0: 1537, 3.0: 945, 4.0: 438, 0.0: 151, 1.0: 42}) Counter({2: 2071, 3: 1042})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print collections.Counter(y_test), collections.Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(5)\n",
    "    plt.xticks(tick_marks, [0,1,2,3,4], rotation=45)\n",
    "    plt.yticks(tick_marks, [0,1,2,3,4])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[   0    0  130   21    0]\n",
      " [   0    0   41    1    0]\n",
      " [   0    0 1238  299    0]\n",
      " [   0    0  233  712    0]\n",
      " [   0    0  429    9    0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEnCAYAAAD/zxugAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYECADCEBAoAwBASKAAAQ/8PSOAdY8ma84oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25aed110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(y_test, predictions)\n",
    "print cm\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
