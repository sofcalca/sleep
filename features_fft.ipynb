{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "\n",
    "from sys import platform as _platform\n",
    "\n",
    "#if _platform =='linux2':\n",
    "#    path = '../data/data_sleep/' \n",
    "#else:\n",
    "    #mets ton path ici et ça devrait marcher :)\n",
    "#    path = \"data\"\n",
    "path=\"data/\"\n",
    "#path = '../data/data_sleep/' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_test = True\n",
    "if(create_test):\n",
    "    data=pd.read_csv(path+\"input_test.csv\")\n",
    "else: \n",
    "    data=pd.read_csv(path+\"input_train.csv\")\n",
    "    labels=pd.read_csv(path+\"challenge_output_data_training_file_sleep_stages_classification.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=data.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filt(y,low, high, freq): \n",
    "    filter_array = [i for i,f in enumerate(freq) if f>=low and f<=high]\n",
    "    return np.array([y[i] for i in filter_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "def make_eeg_features(train, low, high):\n",
    "    fs = 250 # in Hz\n",
    "    N = fs * 15\n",
    "    train_eeg = train.filter(regex='EEG[0-9]*').values\n",
    "    X_fft = np.fft.fft(train_eeg)\n",
    "    freq = np.fft.fftfreq(N, 1./fs)\n",
    "    filtered_freq = filt(freq,low,high,freq)\n",
    "    X_fft = np.apply_along_axis(lambda x: filt(x,low,high,freq), 1 , 1./N * abs(X_fft))\n",
    "    X_fft = pd.DataFrame(X_fft, columns= [\"freq\"+str(f) for f in filtered_freq], index=train.index)\n",
    "    return X_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_fft = make_eeg_features(data, 0.4, 50)\n",
    "#if(create_test):\n",
    "#    X_fft.to_csv(\"data/fft_eeg_test.csv\", index=False)\n",
    "#else :\n",
    "#    X_fft.to_csv(\"data/fft_eeg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_acc_features(train, low, high):\n",
    "    fs = 10 #in Hz\n",
    "    N = fs * 15 #number of samples\n",
    "    accelaration_names = ['ACC_X.','ACC_Y.','ACC_Z.']\n",
    "    result = []\n",
    "    for name in accelaration_names:\n",
    "        train_eeg = train.filter(regex=name+'[0-9]*').values\n",
    "        X_fft = np.fft.fft(train_eeg)\n",
    "        freq = np.fft.fftfreq(N, 1./fs)\n",
    "        filtered_freq = filt(freq,low,high,freq)\n",
    "        X_fft = np.apply_along_axis(lambda x: filt(x,low,high,freq), 1 , 1./N *abs(X_fft))\n",
    "        X_fft = pd.DataFrame(X_fft, columns= [name+\"freq\"+str(f) for f in filtered_freq], index=train.index)\n",
    "        result.append(X_fft)\n",
    "    return pd.concat(result,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fft_acc = make_acc_features(data, 0, 200)\n",
    "#if(create_test):\n",
    "#    fft_acc.to_csv(\"data/fft_acc_test.csv\", index=False)\n",
    "#else:\n",
    "#    fft_acc.to_csv(\"data/fft_acc.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_features_fft(create_test =False, make_files = True):\n",
    "    #si create_test = False: fait les trucs de train, sinon les trucs de test\n",
    "    #si make_files =True, crée les fichiers dans data\n",
    "    X_fft = make_eeg_features(data, 0.4, 50)\n",
    "    if(make_files):\n",
    "        if(create_test):\n",
    "            X_fft.to_csv(\"data/fft_eeg_test.csv\", index=True)\n",
    "        else :\n",
    "            X_fft.to_csv(\"data/fft_eeg.csv\", index=True)\n",
    "    \n",
    "    fft_acc = make_acc_features(data, 0, 200)\n",
    "    if(make_files):    \n",
    "        if(create_test):\n",
    "            fft_acc.to_csv(\"data/fft_acc_test.csv\", index=True)\n",
    "        else:\n",
    "            fft_acc.to_csv(\"data/fft_acc.csv\", index=True)\n",
    "    return X_fft, fft_acc\n",
    "\n",
    "#fft_eeg, fft_acc= make_features_fft(create_test = create_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fft_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_by_zero(array):\n",
    "    \"\"\"\n",
    "    Counts the number of times the signal crosses through zero\n",
    "    \"\"\"\n",
    "    counts = 0\n",
    "    for i in range(0, len(array)-1):\n",
    "        if np.sign(array[i]) != np.sign(array[i+1]):\n",
    "            counts+=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_signal_dic(data):\n",
    "    \"\"\"\n",
    "    Takes train or test data and creates a dictionary separating each signal\n",
    "    \"\"\"\n",
    "    signals = [\"EEG\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]\n",
    "    return {signal: data.filter(regex= \"^\"+signal+\".*\") \n",
    "                for signal in signals\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_stat_features(signal, signal_name):\n",
    "    \"\"\"\n",
    "    Inputs a signal, outputs some important statistics information about it\n",
    "    \"\"\"\n",
    "    centered_signal=signal.apply(lambda x: x - x.mean(),axis=1)\n",
    "    moments = pd.concat(\n",
    "        [signal.mean(axis=1), signal.var(axis=1), centered_signal.skew(axis=1), centered_signal.kurt(axis=1)], \n",
    "        axis=1\n",
    "    )\n",
    "    quantiles = centered_signal.quantile(np.linspace(0,1,11), axis=1).T\n",
    "    quantiles.columns = [\"{}_quantile_{}\".format(signal_name, q) for q in range(0,110,10)]\n",
    "    \n",
    "\n",
    "    moments.columns= [name.format(signal_name) for name in [\"mean_{}\", \"var_{}\", \"skew_{}\", \"kurt_{}\"]]\n",
    "    \n",
    "    return pd.concat([quantiles, moments], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signals = make_signal_dic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cross mean also\n",
    "def make_stats(create_test =False, make_files = True):\n",
    "    \"takes the dict of signals and returns descriptive stats for EEG and ACC\"\n",
    "    stats = {\n",
    "        signal: create_stat_features(signals[signal], signal)\n",
    "        for signal in signals.keys()\n",
    "    }\n",
    "    stats_EEG = pd.concat(\n",
    "        [\n",
    "            stats[\"EEG\"], \n",
    "            pd.Series(signals[\"EEG\"].apply(count_by_zero, axis=1), name=\"EEG_through_0\"),\n",
    "            pd.Series(\n",
    "                signals[\"EEG\"].apply(lambda x: x - x.mean(),axis=1).apply(count_by_zero, axis=1), \n",
    "            name=\"EEG_through_mean\"\n",
    "            )\n",
    "        ],\n",
    "        axis=1\n",
    "        )\n",
    "    if make_files:\n",
    "        if create_test:\n",
    "            stats_EEG.to_csv(\"data/stats_eeg_test.csv\", index=True)\n",
    "        else:\n",
    "            stats_EEG.to_csv(\"data/stats_eeg.csv\", index=False)\n",
    "    stats_ACC = pd.concat([stats[\"ACC_{}\".format(dim)] for dim in [\"X\", \"Y\", \"Z\"]], axis=1)\n",
    "    if make_files:\n",
    "        if create_test:\n",
    "            stats_ACC.to_csv(\"data/stats_acc_test.csv\", index=True)\n",
    "        else:\n",
    "            stats_ACC.to_csv(\"data/stats_acc.csv\", index=True)\n",
    "    return stats_EEG, stats_ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_EEG, stats_ACC=make_stats(create_test =create_test, make_files = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consolidated_amplitude_accelometer(fft_acc):\n",
    "    \"\"\"\n",
    "    Takes the FFT of the accelerometer for each dimension. Returns the L2 norm of the amplitudes for each sequence\n",
    "    \"\"\"\n",
    "    power_by_dimension = {dim: pd.DataFrame() for dim in [\"X\", \"Y\", \"Z\"]}\n",
    "    #go through every column\n",
    "    for col in fft_acc.columns:\n",
    "        #check which dimension it is related to\n",
    "        if col[4]==\"X\":\n",
    "            #squared of the amplitude for each frequency\n",
    "            power_by_dimension[\"X\"][\"{}\".format(col[6:])]=fft_acc[col]**2 \n",
    "        elif col[4]==\"Y\":\n",
    "            power_by_dimension[\"Y\"][\"{}\".format(col[6:])]=fft_acc[col]**2\n",
    "        elif col[4]==\"Z\":\n",
    "            power_by_dimension[\"Z\"][\"{}\".format(col[6:])]=fft_acc[col]**2\n",
    "    return np.sqrt(power_by_dimension[\"X\"] + power_by_dimension[\"Y\"] + power_by_dimension[\"Z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def speed_accelerometer(dict_accelerometer):\n",
    "    \"\"\"\n",
    "    Takes a dictionary with dataframes for each dimension of the accelerometer. Returns consolidated features \n",
    "    (Speed and 1D amplitude)\n",
    "    \"\"\"\n",
    "    #Integral of the acceleration = speed\n",
    "    return np.sqrt( #sqrt of the\n",
    "        sum( #sum over\n",
    "            [\n",
    "                dict_accelerometer[\"ACC_{}\".format(dim)].sum(axis=1)**2 \n",
    "                #squared integral of the acceleration\n",
    "                for dim in [\"X\", \"Y\", \"Z\"] #for each dimension\n",
    "            ]\n",
    "        ) \n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features_accelerometer(create_test =False, make_files = True):\n",
    "    ACC_feats = pd.concat(\n",
    "        [\n",
    "            consolidated_amplitude_accelometer(fft_acc), \n",
    "            pd.Series(speed_accelerometer(signals), name=\"SPEED\")\n",
    "        ],\n",
    "        axis=1\n",
    "        )\n",
    "    if make_files:\n",
    "        if create_test:\n",
    "            ACC_feats.to_csv(\"data/ACC_feats_test.csv\", index=True)\n",
    "        else:\n",
    "            ACC_feats.to_csv(\"data/ACC_feats.csv\", index=True)\n",
    "    return ACC_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ACC_feats=make_features_accelerometer(create_test =create_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-75b17ae07f05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-20-75b17ae07f05>\u001b[0m(2)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 2 \u001b[1;33m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> \n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "freq = np.fft.fftfreq(15*10, 1./250)\n",
    "plt.plot(freq[0:75],result.values[0][0:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_fft.values[0].shape,filt(np.fft.fftfreq(15*250, 1./250),0.4,50,np.fft.fftfreq(15*250, 1./250)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = np.fft.fftfreq(15*250, 1./250)\n",
    "plt.plot(filt(freq,0.4,50,freq),np.abs(X_fft.values[31]))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
