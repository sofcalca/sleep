{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import platform as _platform\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "#if _platform =='linux2':\n",
    "#    path = '../data/data_sleep/' \n",
    "#else:\n",
    "#    #mets ton path ici et Ã§a devrait marcher :)\n",
    "#    path = \"\"\n",
    "path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequencies=pd.read_csv(path+\"data_frequences.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "frequencies=pd.read_csv(path+\"fft_eeg.csv\")\n",
    "frequencies_acc =pd.read_csv(path+\"fft_acc.csv\")\n",
    "\n",
    "stats=pd.read_csv(path+\"data_stat_feats.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "labels=pd.read_csv(path+\"challenge_output_data_training_file_sleep_stages_classification.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_freq_names(low, high, X_columns, prefix = ''):\n",
    "    return [name for name in X_columns \n",
    "            if len(name.split('q'))==2 \n",
    "            and name.split('freq')[0] == prefix\n",
    "            and low<=float(name.split('freq')[1]) \n",
    "            and high>= float(name.split('freq')[1])]\n",
    "def group_frequencies(name, low, high, frequencies, prefix = ''):\n",
    "    frequencies[name]=(1./(high-low) * frequencies[select_freq_names(low,high,frequencies.columns,prefix)]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat = [\"delta\", 'theta', 'alpha1','alpha2', 'beta']\n",
    "#frequencies[\"delta\"]=frequencies[select_freq_names(0,3,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"delta\"]=frequencies[select_freq_names(0,3.99,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"theta\"]=frequencies[select_freq_names(4,7.5,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"alpha\"]=frequencies[select_freq_names(7.5,13.99,frequencies.columns)].sum(axis=1)\n",
    "#frequencies[\"beta\"]=frequencies[select_freq_names(14,50,frequencies.columns)].sum(axis=1)\n",
    "\n",
    "def make_new_feats(frequencies):\n",
    "    group_frequencies(\"delta\", 0.8, 3.99, frequencies)\n",
    "    group_frequencies(\"theta\", 4, 7.499, frequencies)\n",
    "    group_frequencies(\"alpha1\", 7.5, 9.5, frequencies)\n",
    "    group_frequencies(\"alpha2\", 9.5, 13.99, frequencies)\n",
    "    group_frequencies(\"beta\", 14, 50, frequencies)\n",
    "make_new_feats(frequencies)\n",
    "\n",
    "def regroup_acc_freq (frequencies_acc):\n",
    "    for prefix in ['ACC_X.','ACC_Y.','ACC_Z.']:\n",
    "        group_frequencies(prefix+\"smaller_one\",0.01,1, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"one_to_two\",1.01,2, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"two_to_three\",2.01,3, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"three_to_four\",3.01,4, frequencies_acc,prefix)\n",
    "        group_frequencies(prefix+\"more_four\",4,10, frequencies_acc,prefix)\n",
    "regroup_acc_freq (frequencies_acc)\n",
    "\n",
    "prefixes = ['ACC_X.','ACC_Y.','ACC_Z.']\n",
    "frequencies_acc = frequencies_acc[[prefix+ x for x in[\"smaller_one\",\"one_to_two\",\"two_to_three\",'more_four']for prefix in prefixes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha1</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>beta</th>\n",
       "      <th>0_quantile_EEG</th>\n",
       "      <th>10_quantile_EEG</th>\n",
       "      <th>20_quantile_EEG</th>\n",
       "      <th>30_quantile_EEG</th>\n",
       "      <th>40_quantile_EEG</th>\n",
       "      <th>50_quantile_EEG</th>\n",
       "      <th>60_quantile_EEG</th>\n",
       "      <th>70_quantile_EEG</th>\n",
       "      <th>80_quantile_EEG</th>\n",
       "      <th>90_quantile_EEG</th>\n",
       "      <th>100_quantile_EEG</th>\n",
       "      <th>0_quantile_ACC_Z</th>\n",
       "      <th>10_quantile_ACC_Z</th>\n",
       "      <th>20_quantile_ACC_Z</th>\n",
       "      <th>30_quantile_ACC_Z</th>\n",
       "      <th>40_quantile_ACC_Z</th>\n",
       "      <th>50_quantile_ACC_Z</th>\n",
       "      <th>60_quantile_ACC_Z</th>\n",
       "      <th>70_quantile_ACC_Z</th>\n",
       "      <th>80_quantile_ACC_Z</th>\n",
       "      <th>90_quantile_ACC_Z</th>\n",
       "      <th>100_quantile_ACC_Z</th>\n",
       "      <th>0_quantile_ACC_Y</th>\n",
       "      <th>10_quantile_ACC_Y</th>\n",
       "      <th>20_quantile_ACC_Y</th>\n",
       "      <th>30_quantile_ACC_Y</th>\n",
       "      <th>40_quantile_ACC_Y</th>\n",
       "      <th>50_quantile_ACC_Y</th>\n",
       "      <th>60_quantile_ACC_Y</th>\n",
       "      <th>70_quantile_ACC_Y</th>\n",
       "      <th>80_quantile_ACC_Y</th>\n",
       "      <th>90_quantile_ACC_Y</th>\n",
       "      <th>100_quantile_ACC_Y</th>\n",
       "      <th>0_quantile_ACC_X</th>\n",
       "      <th>10_quantile_ACC_X</th>\n",
       "      <th>20_quantile_ACC_X</th>\n",
       "      <th>30_quantile_ACC_X</th>\n",
       "      <th>40_quantile_ACC_X</th>\n",
       "      <th>50_quantile_ACC_X</th>\n",
       "      <th>60_quantile_ACC_X</th>\n",
       "      <th>70_quantile_ACC_X</th>\n",
       "      <th>80_quantile_ACC_X</th>\n",
       "      <th>90_quantile_ACC_X</th>\n",
       "      <th>100_quantile_ACC_X</th>\n",
       "      <th>mean_EEG</th>\n",
       "      <th>mean_ACC_Z</th>\n",
       "      <th>mean_ACC_Y</th>\n",
       "      <th>mean_ACC_X</th>\n",
       "      <th>var_EEG</th>\n",
       "      <th>var_ACC_Z</th>\n",
       "      <th>var_ACC_Y</th>\n",
       "      <th>var_ACC_X</th>\n",
       "      <th>skew_EEG</th>\n",
       "      <th>skew_ACC_Z</th>\n",
       "      <th>skew_ACC_Y</th>\n",
       "      <th>skew_ACC_X</th>\n",
       "      <th>kurt_EEG</th>\n",
       "      <th>kurt_ACC_Z</th>\n",
       "      <th>kurt_ACC_Y</th>\n",
       "      <th>kurt_ACC_X</th>\n",
       "      <th>through_0</th>\n",
       "      <th>ACC_X.smaller_one</th>\n",
       "      <th>ACC_Y.smaller_one</th>\n",
       "      <th>ACC_Z.smaller_one</th>\n",
       "      <th>ACC_X.one_to_two</th>\n",
       "      <th>ACC_Y.one_to_two</th>\n",
       "      <th>ACC_Z.one_to_two</th>\n",
       "      <th>ACC_X.two_to_three</th>\n",
       "      <th>ACC_Y.two_to_three</th>\n",
       "      <th>ACC_Z.two_to_three</th>\n",
       "      <th>ACC_X.more_four</th>\n",
       "      <th>ACC_Y.more_four</th>\n",
       "      <th>ACC_Z.more_four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>3.112700e+04</td>\n",
       "      <td>31095.000000</td>\n",
       "      <td>3.105900e+04</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>3.112900e+04</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "      <td>31129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43379.346974</td>\n",
       "      <td>13380.986171</td>\n",
       "      <td>10436.192508</td>\n",
       "      <td>7810.427290</td>\n",
       "      <td>2818.253073</td>\n",
       "      <td>-67.668904</td>\n",
       "      <td>-24.578816</td>\n",
       "      <td>-15.029817</td>\n",
       "      <td>-9.142491</td>\n",
       "      <td>-4.553969</td>\n",
       "      <td>-0.429837</td>\n",
       "      <td>3.709411</td>\n",
       "      <td>8.344859</td>\n",
       "      <td>14.295154</td>\n",
       "      <td>23.852064</td>\n",
       "      <td>70.926835</td>\n",
       "      <td>389079.403871</td>\n",
       "      <td>394942.680469</td>\n",
       "      <td>401722.919196</td>\n",
       "      <td>418578.215755</td>\n",
       "      <td>441054.816154</td>\n",
       "      <td>464406.560797</td>\n",
       "      <td>487958.291960</td>\n",
       "      <td>511829.372506</td>\n",
       "      <td>533244.536975</td>\n",
       "      <td>548457.120201</td>\n",
       "      <td>553119.307859</td>\n",
       "      <td>508458.001608</td>\n",
       "      <td>512433.331547</td>\n",
       "      <td>520669.693936</td>\n",
       "      <td>538912.377147</td>\n",
       "      <td>560303.097796</td>\n",
       "      <td>583160.354622</td>\n",
       "      <td>606010.389134</td>\n",
       "      <td>628979.842747</td>\n",
       "      <td>650082.743408</td>\n",
       "      <td>665331.568056</td>\n",
       "      <td>670117.303174</td>\n",
       "      <td>463043.459858</td>\n",
       "      <td>467174.530536</td>\n",
       "      <td>474999.947300</td>\n",
       "      <td>492067.066492</td>\n",
       "      <td>512800.096769</td>\n",
       "      <td>534592.475148</td>\n",
       "      <td>556714.590114</td>\n",
       "      <td>578462.955919</td>\n",
       "      <td>599379.979357</td>\n",
       "      <td>614626.710998</td>\n",
       "      <td>619450.027578</td>\n",
       "      <td>-0.307724</td>\n",
       "      <td>467403.641997</td>\n",
       "      <td>585548.917565</td>\n",
       "      <td>537272.507188</td>\n",
       "      <td>8.091409e+03</td>\n",
       "      <td>3.551936e+10</td>\n",
       "      <td>3.488588e+10</td>\n",
       "      <td>3.330232e+10</td>\n",
       "      <td>0.042390</td>\n",
       "      <td>-1.056223e+05</td>\n",
       "      <td>-44216.596762</td>\n",
       "      <td>-9.025399e+04</td>\n",
       "      <td>1.888080</td>\n",
       "      <td>4.234130e+12</td>\n",
       "      <td>7.224458e+13</td>\n",
       "      <td>-4.718321e+13</td>\n",
       "      <td>266.303897</td>\n",
       "      <td>55257.764563</td>\n",
       "      <td>59060.369738</td>\n",
       "      <td>68198.799131</td>\n",
       "      <td>45070.254993</td>\n",
       "      <td>46029.634280</td>\n",
       "      <td>52876.211177</td>\n",
       "      <td>58954.750214</td>\n",
       "      <td>60437.381404</td>\n",
       "      <td>57634.399315</td>\n",
       "      <td>6722.761692</td>\n",
       "      <td>6419.831198</td>\n",
       "      <td>7002.951855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>283395.223148</td>\n",
       "      <td>100010.122134</td>\n",
       "      <td>65039.692153</td>\n",
       "      <td>47325.188288</td>\n",
       "      <td>19907.778963</td>\n",
       "      <td>332.438831</td>\n",
       "      <td>44.725172</td>\n",
       "      <td>16.280377</td>\n",
       "      <td>9.902244</td>\n",
       "      <td>5.071556</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>4.814270</td>\n",
       "      <td>9.619773</td>\n",
       "      <td>15.967630</td>\n",
       "      <td>29.583928</td>\n",
       "      <td>955.988966</td>\n",
       "      <td>561598.622147</td>\n",
       "      <td>565504.824485</td>\n",
       "      <td>564376.304941</td>\n",
       "      <td>559270.237759</td>\n",
       "      <td>557448.144970</td>\n",
       "      <td>564465.259308</td>\n",
       "      <td>581027.070964</td>\n",
       "      <td>606772.710146</td>\n",
       "      <td>635475.764328</td>\n",
       "      <td>658244.766881</td>\n",
       "      <td>662057.095991</td>\n",
       "      <td>670905.568374</td>\n",
       "      <td>672213.290684</td>\n",
       "      <td>668321.467589</td>\n",
       "      <td>660155.944471</td>\n",
       "      <td>655888.106042</td>\n",
       "      <td>658494.868185</td>\n",
       "      <td>668761.620419</td>\n",
       "      <td>686526.242650</td>\n",
       "      <td>708558.016987</td>\n",
       "      <td>726915.544490</td>\n",
       "      <td>729208.429707</td>\n",
       "      <td>586520.188548</td>\n",
       "      <td>587923.715579</td>\n",
       "      <td>583843.126280</td>\n",
       "      <td>575799.732902</td>\n",
       "      <td>571903.857252</td>\n",
       "      <td>576135.801496</td>\n",
       "      <td>588850.829758</td>\n",
       "      <td>609066.069517</td>\n",
       "      <td>634782.817990</td>\n",
       "      <td>656140.274833</td>\n",
       "      <td>661408.888219</td>\n",
       "      <td>0.960328</td>\n",
       "      <td>564113.518866</td>\n",
       "      <td>657677.633921</td>\n",
       "      <td>576190.718726</td>\n",
       "      <td>1.286930e+06</td>\n",
       "      <td>1.127120e+11</td>\n",
       "      <td>1.104874e+11</td>\n",
       "      <td>1.071621e+11</td>\n",
       "      <td>0.536758</td>\n",
       "      <td>2.484497e+06</td>\n",
       "      <td>2012175.965070</td>\n",
       "      <td>3.791622e+06</td>\n",
       "      <td>4.737300</td>\n",
       "      <td>3.619110e+14</td>\n",
       "      <td>2.258636e+15</td>\n",
       "      <td>1.858705e+15</td>\n",
       "      <td>258.887286</td>\n",
       "      <td>185354.795972</td>\n",
       "      <td>194231.355360</td>\n",
       "      <td>219370.283315</td>\n",
       "      <td>149501.520258</td>\n",
       "      <td>148640.948015</td>\n",
       "      <td>169063.960230</td>\n",
       "      <td>197487.618553</td>\n",
       "      <td>197422.005196</td>\n",
       "      <td>186300.527832</td>\n",
       "      <td>22455.088518</td>\n",
       "      <td>20677.336291</td>\n",
       "      <td>22213.360958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6322.290528</td>\n",
       "      <td>2839.570233</td>\n",
       "      <td>2488.058337</td>\n",
       "      <td>1909.686947</td>\n",
       "      <td>733.183142</td>\n",
       "      <td>-57846.411752</td>\n",
       "      <td>-6473.418040</td>\n",
       "      <td>-370.417062</td>\n",
       "      <td>-133.772751</td>\n",
       "      <td>-79.882920</td>\n",
       "      <td>-33.425067</td>\n",
       "      <td>-9.044022</td>\n",
       "      <td>1.006095</td>\n",
       "      <td>1.760171</td>\n",
       "      <td>2.963225</td>\n",
       "      <td>7.786749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.641050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.358505e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.909720</td>\n",
       "      <td>-1.798704e+08</td>\n",
       "      <td>-91635309.917200</td>\n",
       "      <td>-2.384430e+08</td>\n",
       "      <td>-1.469313</td>\n",
       "      <td>-4.018160e+14</td>\n",
       "      <td>-1.061277e+16</td>\n",
       "      <td>-6.333526e+16</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20717.438248</td>\n",
       "      <td>9010.521005</td>\n",
       "      <td>6834.118876</td>\n",
       "      <td>5304.520663</td>\n",
       "      <td>1725.402809</td>\n",
       "      <td>-82.958289</td>\n",
       "      <td>-27.823264</td>\n",
       "      <td>-17.027716</td>\n",
       "      <td>-10.307362</td>\n",
       "      <td>-5.068524</td>\n",
       "      <td>-0.757524</td>\n",
       "      <td>1.227857</td>\n",
       "      <td>3.012414</td>\n",
       "      <td>5.146811</td>\n",
       "      <td>8.339893</td>\n",
       "      <td>26.976275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.528154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.498961e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.187791</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.118877</td>\n",
       "      <td>-9.853041e-02</td>\n",
       "      <td>0.122153</td>\n",
       "      <td>-4.857886e-01</td>\n",
       "      <td>-5.902069e-01</td>\n",
       "      <td>-4.718182e-01</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33601.743420</td>\n",
       "      <td>11411.550337</td>\n",
       "      <td>8865.193597</td>\n",
       "      <td>6942.138178</td>\n",
       "      <td>2054.704165</td>\n",
       "      <td>-47.309534</td>\n",
       "      <td>-14.675546</td>\n",
       "      <td>-8.980321</td>\n",
       "      <td>-5.521182</td>\n",
       "      <td>-2.746643</td>\n",
       "      <td>-0.332591</td>\n",
       "      <td>2.027671</td>\n",
       "      <td>4.745264</td>\n",
       "      <td>8.242451</td>\n",
       "      <td>14.058969</td>\n",
       "      <td>47.394753</td>\n",
       "      <td>91639.477349</td>\n",
       "      <td>98201.173482</td>\n",
       "      <td>116428.759178</td>\n",
       "      <td>170002.357958</td>\n",
       "      <td>192316.672991</td>\n",
       "      <td>193780.850891</td>\n",
       "      <td>193954.602202</td>\n",
       "      <td>194124.333302</td>\n",
       "      <td>194804.309533</td>\n",
       "      <td>195515.181404</td>\n",
       "      <td>198939.906894</td>\n",
       "      <td>71380.506729</td>\n",
       "      <td>79465.537309</td>\n",
       "      <td>101229.183762</td>\n",
       "      <td>149120.401618</td>\n",
       "      <td>162388.346131</td>\n",
       "      <td>166062.022173</td>\n",
       "      <td>166749.380713</td>\n",
       "      <td>167591.188036</td>\n",
       "      <td>168669.216002</td>\n",
       "      <td>170834.217283</td>\n",
       "      <td>180041.535579</td>\n",
       "      <td>200501.676575</td>\n",
       "      <td>207219.445857</td>\n",
       "      <td>220269.167027</td>\n",
       "      <td>285037.057026</td>\n",
       "      <td>325482.690940</td>\n",
       "      <td>331870.768185</td>\n",
       "      <td>332820.496128</td>\n",
       "      <td>333500.145122</td>\n",
       "      <td>334949.232906</td>\n",
       "      <td>335403.784965</td>\n",
       "      <td>336024.663968</td>\n",
       "      <td>-0.315067</td>\n",
       "      <td>194144.996143</td>\n",
       "      <td>168331.881284</td>\n",
       "      <td>332471.073121</td>\n",
       "      <td>1.701812e+02</td>\n",
       "      <td>7.880265e+04</td>\n",
       "      <td>1.316513e+05</td>\n",
       "      <td>7.926813e+04</td>\n",
       "      <td>0.026829</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.685011</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>291.346883</td>\n",
       "      <td>399.276609</td>\n",
       "      <td>305.079191</td>\n",
       "      <td>167.775517</td>\n",
       "      <td>194.342400</td>\n",
       "      <td>176.853885</td>\n",
       "      <td>191.628418</td>\n",
       "      <td>235.663850</td>\n",
       "      <td>204.715626</td>\n",
       "      <td>42.828857</td>\n",
       "      <td>53.168973</td>\n",
       "      <td>47.047349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55944.472094</td>\n",
       "      <td>15094.920164</td>\n",
       "      <td>12152.487994</td>\n",
       "      <td>8964.529673</td>\n",
       "      <td>2749.766834</td>\n",
       "      <td>-27.449899</td>\n",
       "      <td>-9.012322</td>\n",
       "      <td>-5.747950</td>\n",
       "      <td>-3.609769</td>\n",
       "      <td>-1.838396</td>\n",
       "      <td>0.045524</td>\n",
       "      <td>4.116302</td>\n",
       "      <td>9.476140</td>\n",
       "      <td>16.365352</td>\n",
       "      <td>27.402314</td>\n",
       "      <td>82.504026</td>\n",
       "      <td>424299.974866</td>\n",
       "      <td>426528.414206</td>\n",
       "      <td>426645.396649</td>\n",
       "      <td>432124.918890</td>\n",
       "      <td>582170.599627</td>\n",
       "      <td>808454.196385</td>\n",
       "      <td>986527.545088</td>\n",
       "      <td>1224155.753420</td>\n",
       "      <td>1306315.719800</td>\n",
       "      <td>1310768.407150</td>\n",
       "      <td>1317054.647870</td>\n",
       "      <td>1391781.490910</td>\n",
       "      <td>1395128.072550</td>\n",
       "      <td>1401799.786780</td>\n",
       "      <td>1403900.532040</td>\n",
       "      <td>1405352.141420</td>\n",
       "      <td>1405636.579820</td>\n",
       "      <td>1405869.241000</td>\n",
       "      <td>1412457.320780</td>\n",
       "      <td>1487671.497720</td>\n",
       "      <td>1526567.382960</td>\n",
       "      <td>1529385.905650</td>\n",
       "      <td>1245765.946220</td>\n",
       "      <td>1247935.344330</td>\n",
       "      <td>1248558.781110</td>\n",
       "      <td>1248973.446340</td>\n",
       "      <td>1249024.790550</td>\n",
       "      <td>1249045.440790</td>\n",
       "      <td>1249050.462650</td>\n",
       "      <td>1269089.470600</td>\n",
       "      <td>1299826.224730</td>\n",
       "      <td>1302429.700470</td>\n",
       "      <td>1302794.057530</td>\n",
       "      <td>-0.019021</td>\n",
       "      <td>810118.297996</td>\n",
       "      <td>1403606.253900</td>\n",
       "      <td>1248824.166290</td>\n",
       "      <td>5.387287e+02</td>\n",
       "      <td>9.166023e+05</td>\n",
       "      <td>6.407979e+05</td>\n",
       "      <td>4.934285e+05</td>\n",
       "      <td>0.261775</td>\n",
       "      <td>1.920846e-01</td>\n",
       "      <td>0.078766</td>\n",
       "      <td>1.030035e-01</td>\n",
       "      <td>1.900467</td>\n",
       "      <td>2.069295e-01</td>\n",
       "      <td>1.249703e-01</td>\n",
       "      <td>1.569532e-01</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>852.121895</td>\n",
       "      <td>1225.520195</td>\n",
       "      <td>1299.806604</td>\n",
       "      <td>291.793296</td>\n",
       "      <td>325.416886</td>\n",
       "      <td>356.170923</td>\n",
       "      <td>394.255615</td>\n",
       "      <td>434.043896</td>\n",
       "      <td>485.958391</td>\n",
       "      <td>90.726118</td>\n",
       "      <td>94.976595</td>\n",
       "      <td>103.744164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49805983.681107</td>\n",
       "      <td>17620750.984793</td>\n",
       "      <td>11448208.252360</td>\n",
       "      <td>8333891.437587</td>\n",
       "      <td>3483159.136385</td>\n",
       "      <td>-7.846800</td>\n",
       "      <td>-3.336069</td>\n",
       "      <td>-2.250318</td>\n",
       "      <td>-1.371010</td>\n",
       "      <td>1.549733</td>\n",
       "      <td>26.079463</td>\n",
       "      <td>74.284299</td>\n",
       "      <td>121.039011</td>\n",
       "      <td>189.060611</td>\n",
       "      <td>2530.299222</td>\n",
       "      <td>168434.316703</td>\n",
       "      <td>1678757.317340</td>\n",
       "      <td>1680153.808660</td>\n",
       "      <td>1680473.853470</td>\n",
       "      <td>1680593.335530</td>\n",
       "      <td>1680729.325810</td>\n",
       "      <td>1680813.125630</td>\n",
       "      <td>1680938.709620</td>\n",
       "      <td>1682200.457600</td>\n",
       "      <td>1682284.836810</td>\n",
       "      <td>1682347.954830</td>\n",
       "      <td>1682421.220660</td>\n",
       "      <td>1678843.737320</td>\n",
       "      <td>1679413.596860</td>\n",
       "      <td>1679591.932640</td>\n",
       "      <td>1679770.554930</td>\n",
       "      <td>1680077.181540</td>\n",
       "      <td>1680958.583470</td>\n",
       "      <td>1681100.457470</td>\n",
       "      <td>1681604.195970</td>\n",
       "      <td>1682233.092470</td>\n",
       "      <td>1682330.681370</td>\n",
       "      <td>1682421.220660</td>\n",
       "      <td>1677640.565260</td>\n",
       "      <td>1677951.780770</td>\n",
       "      <td>1678947.447500</td>\n",
       "      <td>1679335.338040</td>\n",
       "      <td>1679647.405820</td>\n",
       "      <td>1680023.506520</td>\n",
       "      <td>1680340.821460</td>\n",
       "      <td>1681770.266940</td>\n",
       "      <td>1682160.723500</td>\n",
       "      <td>1682321.069130</td>\n",
       "      <td>1682421.220660</td>\n",
       "      <td>14.288895</td>\n",
       "      <td>1679657.071140</td>\n",
       "      <td>1679751.107980</td>\n",
       "      <td>1678497.393070</td>\n",
       "      <td>2.270588e+08</td>\n",
       "      <td>6.255575e+11</td>\n",
       "      <td>6.287287e+11</td>\n",
       "      <td>6.166753e+11</td>\n",
       "      <td>13.196885</td>\n",
       "      <td>8.269454e+04</td>\n",
       "      <td>268860.079436</td>\n",
       "      <td>9.353668e+05</td>\n",
       "      <td>305.230097</td>\n",
       "      <td>3.546717e+16</td>\n",
       "      <td>7.371408e+16</td>\n",
       "      <td>3.841563e+16</td>\n",
       "      <td>3008.000000</td>\n",
       "      <td>1520394.435876</td>\n",
       "      <td>1495382.004802</td>\n",
       "      <td>1526600.035678</td>\n",
       "      <td>1063447.474825</td>\n",
       "      <td>977418.806628</td>\n",
       "      <td>997320.652283</td>\n",
       "      <td>1342173.502363</td>\n",
       "      <td>1288287.269416</td>\n",
       "      <td>1117223.001579</td>\n",
       "      <td>163937.806183</td>\n",
       "      <td>165207.506982</td>\n",
       "      <td>163803.108806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 delta            theta           alpha1          alpha2  \\\n",
       "count     31129.000000     31129.000000     31129.000000    31129.000000   \n",
       "mean      43379.346974     13380.986171     10436.192508     7810.427290   \n",
       "std      283395.223148    100010.122134     65039.692153    47325.188288   \n",
       "min        6322.290528      2839.570233      2488.058337     1909.686947   \n",
       "25%       20717.438248      9010.521005      6834.118876     5304.520663   \n",
       "50%       33601.743420     11411.550337      8865.193597     6942.138178   \n",
       "75%       55944.472094     15094.920164     12152.487994     8964.529673   \n",
       "max    49805983.681107  17620750.984793  11448208.252360  8333891.437587   \n",
       "\n",
       "                 beta  0_quantile_EEG  10_quantile_EEG  20_quantile_EEG  \\\n",
       "count    31129.000000    31129.000000     31129.000000     31129.000000   \n",
       "mean      2818.253073      -67.668904       -24.578816       -15.029817   \n",
       "std      19907.778963      332.438831        44.725172        16.280377   \n",
       "min        733.183142   -57846.411752     -6473.418040      -370.417062   \n",
       "25%       1725.402809      -82.958289       -27.823264       -17.027716   \n",
       "50%       2054.704165      -47.309534       -14.675546        -8.980321   \n",
       "75%       2749.766834      -27.449899        -9.012322        -5.747950   \n",
       "max    3483159.136385       -7.846800        -3.336069        -2.250318   \n",
       "\n",
       "       30_quantile_EEG  40_quantile_EEG  50_quantile_EEG  60_quantile_EEG  \\\n",
       "count     31129.000000     31129.000000     31129.000000     31129.000000   \n",
       "mean         -9.142491        -4.553969        -0.429837         3.709411   \n",
       "std           9.902244         5.071556         1.948052         4.814270   \n",
       "min        -133.772751       -79.882920       -33.425067        -9.044022   \n",
       "25%         -10.307362        -5.068524        -0.757524         1.227857   \n",
       "50%          -5.521182        -2.746643        -0.332591         2.027671   \n",
       "75%          -3.609769        -1.838396         0.045524         4.116302   \n",
       "max          -1.371010         1.549733        26.079463        74.284299   \n",
       "\n",
       "       70_quantile_EEG  80_quantile_EEG  90_quantile_EEG  100_quantile_EEG  \\\n",
       "count     31129.000000     31129.000000     31129.000000      31129.000000   \n",
       "mean          8.344859        14.295154        23.852064         70.926835   \n",
       "std           9.619773        15.967630        29.583928        955.988966   \n",
       "min           1.006095         1.760171         2.963225          7.786749   \n",
       "25%           3.012414         5.146811         8.339893         26.976275   \n",
       "50%           4.745264         8.242451        14.058969         47.394753   \n",
       "75%           9.476140        16.365352        27.402314         82.504026   \n",
       "max         121.039011       189.060611      2530.299222     168434.316703   \n",
       "\n",
       "       0_quantile_ACC_Z  10_quantile_ACC_Z  20_quantile_ACC_Z  \\\n",
       "count      31129.000000       31129.000000       31129.000000   \n",
       "mean      389079.403871      394942.680469      401722.919196   \n",
       "std       561598.622147      565504.824485      564376.304941   \n",
       "min            0.000000           0.000000           0.000000   \n",
       "25%            0.000000           0.000000           0.000000   \n",
       "50%        91639.477349       98201.173482      116428.759178   \n",
       "75%       424299.974866      426528.414206      426645.396649   \n",
       "max      1678757.317340     1680153.808660     1680473.853470   \n",
       "\n",
       "       30_quantile_ACC_Z  40_quantile_ACC_Z  50_quantile_ACC_Z  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       418578.215755      441054.816154      464406.560797   \n",
       "std        559270.237759      557448.144970      564465.259308   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%        170002.357958      192316.672991      193780.850891   \n",
       "75%        432124.918890      582170.599627      808454.196385   \n",
       "max       1680593.335530     1680729.325810     1680813.125630   \n",
       "\n",
       "       60_quantile_ACC_Z  70_quantile_ACC_Z  80_quantile_ACC_Z  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       487958.291960      511829.372506      533244.536975   \n",
       "std        581027.070964      606772.710146      635475.764328   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%        193954.602202      194124.333302      194804.309533   \n",
       "75%        986527.545088     1224155.753420     1306315.719800   \n",
       "max       1680938.709620     1682200.457600     1682284.836810   \n",
       "\n",
       "       90_quantile_ACC_Z  100_quantile_ACC_Z  0_quantile_ACC_Y  \\\n",
       "count       31129.000000        31129.000000      31129.000000   \n",
       "mean       548457.120201       553119.307859     508458.001608   \n",
       "std        658244.766881       662057.095991     670905.568374   \n",
       "min             0.000000            0.000000          0.000000   \n",
       "25%             0.000000            0.000000          0.000000   \n",
       "50%        195515.181404       198939.906894      71380.506729   \n",
       "75%       1310768.407150      1317054.647870    1391781.490910   \n",
       "max       1682347.954830      1682421.220660    1678843.737320   \n",
       "\n",
       "       10_quantile_ACC_Y  20_quantile_ACC_Y  30_quantile_ACC_Y  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       512433.331547      520669.693936      538912.377147   \n",
       "std        672213.290684      668321.467589      660155.944471   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%         79465.537309      101229.183762      149120.401618   \n",
       "75%       1395128.072550     1401799.786780     1403900.532040   \n",
       "max       1679413.596860     1679591.932640     1679770.554930   \n",
       "\n",
       "       40_quantile_ACC_Y  50_quantile_ACC_Y  60_quantile_ACC_Y  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       560303.097796      583160.354622      606010.389134   \n",
       "std        655888.106042      658494.868185      668761.620419   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%        162388.346131      166062.022173      166749.380713   \n",
       "75%       1405352.141420     1405636.579820     1405869.241000   \n",
       "max       1680077.181540     1680958.583470     1681100.457470   \n",
       "\n",
       "       70_quantile_ACC_Y  80_quantile_ACC_Y  90_quantile_ACC_Y  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       628979.842747      650082.743408      665331.568056   \n",
       "std        686526.242650      708558.016987      726915.544490   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%        167591.188036      168669.216002      170834.217283   \n",
       "75%       1412457.320780     1487671.497720     1526567.382960   \n",
       "max       1681604.195970     1682233.092470     1682330.681370   \n",
       "\n",
       "       100_quantile_ACC_Y  0_quantile_ACC_X  10_quantile_ACC_X  \\\n",
       "count        31129.000000      31129.000000       31129.000000   \n",
       "mean        670117.303174     463043.459858      467174.530536   \n",
       "std         729208.429707     586520.188548      587923.715579   \n",
       "min              0.000000          0.000000           0.000000   \n",
       "25%              0.000000          0.000000           0.000000   \n",
       "50%         180041.535579     200501.676575      207219.445857   \n",
       "75%        1529385.905650    1245765.946220     1247935.344330   \n",
       "max        1682421.220660    1677640.565260     1677951.780770   \n",
       "\n",
       "       20_quantile_ACC_X  30_quantile_ACC_X  40_quantile_ACC_X  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       474999.947300      492067.066492      512800.096769   \n",
       "std        583843.126280      575799.732902      571903.857252   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%        220269.167027      285037.057026      325482.690940   \n",
       "75%       1248558.781110     1248973.446340     1249024.790550   \n",
       "max       1678947.447500     1679335.338040     1679647.405820   \n",
       "\n",
       "       50_quantile_ACC_X  60_quantile_ACC_X  70_quantile_ACC_X  \\\n",
       "count       31129.000000       31129.000000       31129.000000   \n",
       "mean       534592.475148      556714.590114      578462.955919   \n",
       "std        576135.801496      588850.829758      609066.069517   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%        331870.768185      332820.496128      333500.145122   \n",
       "75%       1249045.440790     1249050.462650     1269089.470600   \n",
       "max       1680023.506520     1680340.821460     1681770.266940   \n",
       "\n",
       "       80_quantile_ACC_X  90_quantile_ACC_X  100_quantile_ACC_X      mean_EEG  \\\n",
       "count       31129.000000       31129.000000        31129.000000  31129.000000   \n",
       "mean       599379.979357      614626.710998       619450.027578     -0.307724   \n",
       "std        634782.817990      656140.274833       661408.888219      0.960328   \n",
       "min             0.000000           0.000000            0.000000    -12.641050   \n",
       "25%             0.000000           0.000000            0.000000     -0.528154   \n",
       "50%        334949.232906      335403.784965       336024.663968     -0.315067   \n",
       "75%       1299826.224730     1302429.700470      1302794.057530     -0.019021   \n",
       "max       1682160.723500     1682321.069130      1682421.220660     14.288895   \n",
       "\n",
       "           mean_ACC_Z      mean_ACC_Y      mean_ACC_X       var_EEG  \\\n",
       "count    31129.000000    31129.000000    31129.000000  3.112900e+04   \n",
       "mean    467403.641997   585548.917565   537272.507188  8.091409e+03   \n",
       "std     564113.518866   657677.633921   576190.718726  1.286930e+06   \n",
       "min          0.000000        0.000000        0.000000  6.358505e+00   \n",
       "25%          0.000000        0.000000        0.000000  5.498961e+01   \n",
       "50%     194144.996143   168331.881284   332471.073121  1.701812e+02   \n",
       "75%     810118.297996  1403606.253900  1248824.166290  5.387287e+02   \n",
       "max    1679657.071140  1679751.107980  1678497.393070  2.270588e+08   \n",
       "\n",
       "          var_ACC_Z     var_ACC_Y     var_ACC_X      skew_EEG    skew_ACC_Z  \\\n",
       "count  3.112900e+04  3.112900e+04  3.112900e+04  31129.000000  3.112700e+04   \n",
       "mean   3.551936e+10  3.488588e+10  3.330232e+10      0.042390 -1.056223e+05   \n",
       "std    1.127120e+11  1.104874e+11  1.071621e+11      0.536758  2.484497e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00     -9.909720 -1.798704e+08   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00     -0.187791  0.000000e+00   \n",
       "50%    7.880265e+04  1.316513e+05  7.926813e+04      0.026829  0.000000e+00   \n",
       "75%    9.166023e+05  6.407979e+05  4.934285e+05      0.261775  1.920846e-01   \n",
       "max    6.255575e+11  6.287287e+11  6.166753e+11     13.196885  8.269454e+04   \n",
       "\n",
       "            skew_ACC_Y    skew_ACC_X      kurt_EEG    kurt_ACC_Z  \\\n",
       "count     31095.000000  3.105900e+04  31129.000000  3.112900e+04   \n",
       "mean     -44216.596762 -9.025399e+04      1.888080  4.234130e+12   \n",
       "std     2012175.965070  3.791622e+06      4.737300  3.619110e+14   \n",
       "min   -91635309.917200 -2.384430e+08     -1.469313 -4.018160e+14   \n",
       "25%          -0.118877 -9.853041e-02      0.122153 -4.857886e-01   \n",
       "50%           0.000000  0.000000e+00      0.685011  0.000000e+00   \n",
       "75%           0.078766  1.030035e-01      1.900467  2.069295e-01   \n",
       "max      268860.079436  9.353668e+05    305.230097  3.546717e+16   \n",
       "\n",
       "         kurt_ACC_Y    kurt_ACC_X     through_0  ACC_X.smaller_one  \\\n",
       "count  3.112900e+04  3.112900e+04  31129.000000       31129.000000   \n",
       "mean   7.224458e+13 -4.718321e+13    266.303897       55257.764563   \n",
       "std    2.258636e+15  1.858705e+15    258.887286      185354.795972   \n",
       "min   -1.061277e+16 -6.333526e+16     11.000000           0.000000   \n",
       "25%   -5.902069e-01 -4.718182e-01    109.000000           0.000000   \n",
       "50%    0.000000e+00  0.000000e+00    204.000000         291.346883   \n",
       "75%    1.249703e-01  1.569532e-01    318.000000         852.121895   \n",
       "max    7.371408e+16  3.841563e+16   3008.000000     1520394.435876   \n",
       "\n",
       "       ACC_Y.smaller_one  ACC_Z.smaller_one  ACC_X.one_to_two  \\\n",
       "count       31129.000000       31129.000000      31129.000000   \n",
       "mean        59060.369738       68198.799131      45070.254993   \n",
       "std        194231.355360      219370.283315     149501.520258   \n",
       "min             0.000000           0.000000          0.000000   \n",
       "25%             0.000000           0.000000          0.000000   \n",
       "50%           399.276609         305.079191        167.775517   \n",
       "75%          1225.520195        1299.806604        291.793296   \n",
       "max       1495382.004802     1526600.035678    1063447.474825   \n",
       "\n",
       "       ACC_Y.one_to_two  ACC_Z.one_to_two  ACC_X.two_to_three  \\\n",
       "count      31129.000000      31129.000000        31129.000000   \n",
       "mean       46029.634280      52876.211177        58954.750214   \n",
       "std       148640.948015     169063.960230       197487.618553   \n",
       "min            0.000000          0.000000            0.000000   \n",
       "25%            0.000000          0.000000            0.000000   \n",
       "50%          194.342400        176.853885          191.628418   \n",
       "75%          325.416886        356.170923          394.255615   \n",
       "max       977418.806628     997320.652283      1342173.502363   \n",
       "\n",
       "       ACC_Y.two_to_three  ACC_Z.two_to_three  ACC_X.more_four  \\\n",
       "count        31129.000000        31129.000000     31129.000000   \n",
       "mean         60437.381404        57634.399315      6722.761692   \n",
       "std         197422.005196       186300.527832     22455.088518   \n",
       "min              0.000000            0.000000         0.000000   \n",
       "25%              0.000000            0.000000         0.000000   \n",
       "50%            235.663850          204.715626        42.828857   \n",
       "75%            434.043896          485.958391        90.726118   \n",
       "max        1288287.269416      1117223.001579    163937.806183   \n",
       "\n",
       "       ACC_Y.more_four  ACC_Z.more_four  \n",
       "count     31129.000000     31129.000000  \n",
       "mean       6419.831198      7002.951855  \n",
       "std       20677.336291     22213.360958  \n",
       "min           0.000000         0.000000  \n",
       "25%           0.000000         0.000000  \n",
       "50%          53.168973        47.047349  \n",
       "75%          94.976595       103.744164  \n",
       "max      165207.506982    163803.108806  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([frequencies[new_feat], stats, frequencies_acc], axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = train.drop([\"skew_ACC_X\",\"skew_ACC_Y\", \"skew_ACC_Z\"], axis=1)\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_sc = scaler.transform(X)\n",
    "X_columns = train.columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sc, labels[\"TARGET\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "('GBR', 3, ' Best learning_rate and associated score', ': ', {'learning_rate': 0.04}, 0.49142673573465046)\n",
      "('GBC - accuracy Score on test_data : ', 0.49726951493735944)\n",
      "('GBC - kappa Score on test_data : ', 1.1041930593156906e-16)\n",
      "('GBC- kappa Score on train data : ', 0.0)\n",
      "*******************************************************************************\n",
      "('GBR', 4, ' Best learning_rate and associated score', ': ', {'learning_rate': 0.04}, 0.49142673573465046)\n",
      "('GBC - accuracy Score on test_data : ', 0.49726951493735944)\n",
      "('GBC - kappa Score on test_data : ', 1.1041930593156906e-16)\n",
      "('GBC- kappa Score on train data : ', 0.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2bf1841dbe88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'from sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\\nfrom sklearn.grid_search import GridSearchCV\\ntuned_parameters = {\\'learning_rate\\': [ 0.04, 0.02, 0.01,0.008,0.005,0.001],#[0.01, 0.03, 0.06, 0.1, 0.4],\\n                    }\\n\\nfor max_depth in [3,4,5,6,7,10]:\\n    gb = GridSearchCV(GradientBoostingClassifier( n_estimators=1), tuned_parameters, cv=5,\\n                       n_jobs = 3)\\n    gb.fit(X_train, y_train)\\n    predicted_label = gb.predict(X_test)\\n    print \"*******************************************************************************\"\\n    print(\"GBR\", max_depth, \" Best learning_rate and associated score\", \": \", gb.best_params_, gb.best_score_)\\n    print(\"GBC - accuracy Score on test_data : \", accuracy_score(y_test, predicted_label))\\n    print(\"GBC - kappa Score on test_data : \", cohen_kappa_score(y_test, predicted_label))\\n    print(\"GBC- kappa Score on train data : \", cohen_kappa_score(y_train, gb.predict(X_train)))'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    810\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m                         \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = {'learning_rate': [ 0.04, 0.02, 0.01,0.008,0.005,0.001],#[0.01, 0.03, 0.06, 0.1, 0.4],\n",
    "                    }\n",
    "\n",
    "for max_depth in [3,4,5,6,7,10]:\n",
    "    gb = GridSearchCV(GradientBoostingClassifier( n_estimators=1000), tuned_parameters, cv=5,\n",
    "                       n_jobs = 3)\n",
    "    gb.fit(X_train, y_train)\n",
    "    predicted_label = gb.predict(X_test)\n",
    "    print \"*******************************************************************************\"\n",
    "    print(\"GBR\", max_depth, \" Best learning_rate and associated score\", \": \", gb.best_params_, gb.best_score_)\n",
    "    print(\"GBC - accuracy Score on test_data : \", accuracy_score(y_test, predicted_label))\n",
    "    print(\"GBC - kappa Score on test_data : \", cohen_kappa_score(y_test, predicted_label))\n",
    "    print(\"GBC- kappa Score on train data : \", cohen_kappa_score(y_train, gb.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
